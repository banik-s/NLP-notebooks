{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f598d1ff-d25e-49c0-be60-23619a96f688",
   "metadata": {},
   "source": [
    "### Stemming vs. Lemmatization in NLP\n",
    "Both stemming and lemmatization are text normalization techniques used in Natural Language Processing (NLP) to reduce words to their root forms. However, they differ in their approach and accuracy.\n",
    "\n",
    "1. Stemming\n",
    "Definition:\n",
    "\n",
    "Stemming reduces a word to its base/root form by removing suffixes.\n",
    "It does not necessarily produce a real word.\n",
    "\n",
    "Running ---------------\trun\n",
    "Studies --------------\tstudi\n",
    "Happily ------------\thappi\n",
    "Organization -------\torganiz\n",
    "\n",
    "2. Lemmatization\n",
    "Definition:\n",
    "\n",
    "Lemmatization reduces words to their dictionary base form (lemma) based on morphology.\n",
    "It ensures that the output is a valid meaningful word.\n",
    "\n",
    "Running ---------\trun\n",
    "Studies --------\tstudy\n",
    "Happily --------\thappy\n",
    "Better ---------\tgood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7ce199-2627-41a0-8720-14fa9a6cf82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813179e3-2d09-4088-80ba-ec39b156cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "adjustable | adjust\n",
      "rafting | raft\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \"|\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3e8e5-0bcb-4d84-9435-cf3293388383",
   "metadata": {},
   "source": [
    "### Lemmatization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f3b3eb-25bd-448b-992f-7208c9a7a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1122fb1-d8e2-48d3-9c98-01765c42d024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | eat\n",
      "adjustable | adjustable\n",
      "rafting | raft\n",
      "ability | ability\n",
      "meeting | meet\n",
      "better | well\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing\")\n",
    "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d0c16-9e13-4316-8899-c5cfec92dd95",
   "metadata": {},
   "source": [
    "### Customizing lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdd8d308-c976-4caa-b00d-1545b0fe13f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e784f9a-60c1-4ec4-9241-8af4a67b3457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      "! | !\n",
      "I | I\n",
      "am | be\n",
      "exhausted | exhaust\n"
     ]
    }
   ],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
    "\n",
    "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
    "for token in doc:\n",
    "    print(token.text, \"|\", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34937c10-6e60-44a1-b973-1e3ebb304336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brah"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1f06ab6-1834-4e30-b37c-8e8f5b7981b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brother'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6].lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32de47b-c2af-48e9-8559-dd02445f2c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
